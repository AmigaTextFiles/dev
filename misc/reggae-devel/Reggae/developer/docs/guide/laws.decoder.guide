@database laws.decoder.guide
@rem Source: class.c
@rem Generated with RoboDoc v3.1a (Jul  3 2005)
@rem RoboDoc is copyright 1994-1997 by Maverick Software Development
@node Main laws.decoder.guide
@{jcenter}
@{fg highlight}@{b}TABLE OF CONTENTS@{ub}@{fg text}

@{"laws.decoder/background         " Link "background"}
@{"laws.decoder/MMA_StreamPosFrames" Link "MMA_StreamPosFrames"}
@{"laws.decoder/MMA_StreamPosTime  " Link "MMA_StreamPosTime"}
@{"laws.decoder/MMM_Pull           " Link "MMM_Pull"}
@{jleft}
@endnode
@Node "background" "laws.decoder/background"
@{fg shine}laws.decoder/background@{fg text}

@{b}DESCRIPTION@{ub}
     This class is a Reggae decoder for decoding non-linearly quantized
     8-bit PCM data according to two CCITT standards: mu-law and A-law.
     These nonlinear quantizations are used for example in WAVE format as
     subtypes 6 and 7. Nonlinear quantization improves subjective signal to
     noise ratio compared to linear 8-bit PCM coding. A laws.decoder object
     has one input (port 0) and one output (port 1). The input accepts
     following formats (all formats are with interleaved channels):

     - MMF_AUDIO_MULAW, 8-bit unsigned integers, mu-law quantization curve.
     - MMF_AUDIO_ALAW, 8-bit unsigned integers, A-law quantization curve.

     On the output an object can produce following formats:

     - MMFC_AUDIO_INT16, 16-bit signed interegs,
     - MMFC_AUDIO_INT32, 32-bit signed integers,
     - MMFC_AUDIO_FLOAT32, 32-bit single precision floats, normalized to
       (-1.0, +1.0) range.

     In contrast to classing decoding method, which is using a lookup table 
     of 128 words, laws.decoder calculates output samples from input bytes
     directly, which is faster especially in AltiVec version.


@{b}NEW ATTRIBUTES@{ub}
       Attributes applicability:
         I - may be set at creation time.
         S - may be set on an existing object.
         G - may be get from an object.
         P - may be set for an object's port.
         Q - may be queried from an object's port.

       @{"MMA_StreamPosFrames" Link "MMA_StreamPosFrames"}      (V51) [..G.Q], UQUAD*
       @{"MMA_StreamPosTime" Link "MMA_StreamPosTime"}        (V51) [..G.Q], UQUAD*


@{b}NEW METHODS@{ub}
       @{"MMM_Pull" Link "MMM_Pull"}(port, buffer, length)  (V50)


@endnode
@Node "MMA_StreamPosFrames" "laws.decoder/MMA_StreamPosFrames"
@{fg shine}laws.decoder/MMA_StreamPosFrames@{fg text}

@{b}NAME@{ub}
       @{b}MMA_StreamPosFrames@{ub} (V51) [..G.Q], UQUAD*


@{b}FUNCTION@{ub}
       Returns current absolute stream position in sample frames. It is
       exactly the number of the whole sample frames pulled from object's
       output. As laws.decoder object has no information about sound
       channels, it queries the object connected to the input of
       MMA_Sound_Channels with @{"MMM_GetPortFwd" Link "multimedia.class.guide/MMM_GetPortFwd"}() method.


@{b}NOTES@{ub}
       This is a 64-bit attribute passed by pointer to UQUAD variable, not
       by value.


@endnode
@Node "MMA_StreamPosTime" "laws.decoder/MMA_StreamPosTime"
@{fg shine}laws.decoder/MMA_StreamPosTime@{fg text}

@{b}NAME@{ub}
       @{b}MMA_StreamPosTime@{ub} (V51) [..G.Q], UQUAD*


@{b}FUNCTION@{ub}
       Returns absolute stream time position in microseconds. This time
       position is strictly based on MMA_Sound_SampleRate, and reflects
       only the whole sample frames already pulled from the object output.
       The exact formula is:

       time_pos = whole_frames_pulled / MMA_Sound_SampleRate

       The class queries the object connected to the object's input about
       MMA_Sound_SampleRate and MMA_Sound_Channels with @{"MMM_GetPortFwd" Link "multimedia.class.guide/MMM_GetPortFwd"}()
       method.


@{b}NOTES@{ub}
       This is a 64-bit attribute passed by pointer to UQUAD variable, not
       by value.

       Returned time is not in any way related to playback time for two
       reasons: firstly, there can be an unknown number of buffers between
       the decoder and the output, secondly, playback samplerate may
       be different than those specified in the stream header.


@endnode
@Node "MMM_Pull" "laws.decoder/MMM_Pull"
@{fg shine}laws.decoder/MMM_Pull@{fg text}

@{b}NAME@{ub}
       @{b}MMM_Pull@{ub} (V50)


@{b}SYNOPSIS@{ub}
       bytes = DoMethod(obj, @{b}MMM_Pull@{ub}, ULONG port, APTR buffer, ULONG
         length);


@{b}FUNCTION@{ub}
       Places required amount of sound common format data (in bytes) in the
       specified buffer. The method calculates how many bytes it must pull
       from the previous object, to get required amount of output. Then data
       are pulled, converted and placed in the buffer. Note that requested 
       number of bytes should be a multiply of sample frame size (for
       example 8 bytes for stereo sound if MMFC_INT32 is set as output
       format). If it is not, it will be rounded down to the nearest sample
       frame boundary, left bytes are undefined.


@{b}INPUTS@{ub}
       - obj, object to perform the method on.
       - port, number of port is always 1 (the output port).
       - buffer, a memory buffer for pulled data, must be aligned to 16-byte
         boundary (preferrably allocated with MediaAllocMem()).
       - length, amount of pulled data in bytes. Will be rounded down to the
         nearest sample frame boundary.


@{b}RESULT@{ub}
       - bytes, number of bytes pulled actually.


@endnode

