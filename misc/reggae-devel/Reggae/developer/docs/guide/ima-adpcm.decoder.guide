@database ima-adpcm.decoder.guide
@rem Source: class.c
@rem Generated with RoboDoc v3.1a (Jul  3 2005)
@rem RoboDoc is copyright 1994-1997 by Maverick Software Development
@node Main ima-adpcm.decoder.guide
@{jcenter}
@{fg highlight}@{b}TABLE OF CONTENTS@{ub}@{fg text}

@{"ima-adpcm.decoder/background         " Link "background"}
@{"ima-adpcm.decoder/MMA_StreamPosFrames" Link "MMA_StreamPosFrames"}
@{"ima-adpcm.decoder/MMA_StreamPosTime  " Link "MMA_StreamPosTime"}
@{"ima-adpcm.decoder/MMM_Pull           " Link "MMM_Pull"}
@{jleft}
@endnode
@Node "background" "ima-adpcm.decoder/background"
@{fg shine}ima-adpcm.decoder/background@{fg text}

@{b}DESCRIPTION@{ub}
  This class is a Reggae decoder for decoding IMA-ADPCM streams (also known
  as DVI-ADPCM) found in WAVE subformat 17 files. It is a simple adaptive
  PCM algorithm using 3 or 4 bits per sample, whit nonlinear delta table and
  first order predictor. The decoder handles 3- and 4-bit streams with any
  number of channels up to 256. An ima-adpcm.decoder object has one input
  (port 0) and one output (port 1). The input accepts following format:

    - MMF_AUDIO_IMA_ADPCM

  On the output an object can produce following formats:

    - MMFC_AUDIO_INT16, 16-bit signed interegs,


@{b}NEW ATTRIBUTES@{ub}
   Attributes applicability:
     I - may be set at creation time.
     S - may be set on an existing object.
     G - may be get from an object.
     P - may be set for an object's port.
     Q - may be queried from an object's port.

   @{"MMA_StreamPosFrames" Link "MMA_StreamPosFrames"}      (V51) [..G.Q], UQUAD*
   @{"MMA_StreamPosTime" Link "MMA_StreamPosTime"}        (V51) [..G.Q], UQUAD*


@{b}NEW METHODS@{ub}
   @{"MMM_Pull" Link "MMM_Pull"}(port, buffer, length)  (V50)


@endnode
@Node "MMA_StreamPosFrames" "ima-adpcm.decoder/MMA_StreamPosFrames"
@{fg shine}ima-adpcm.decoder/MMA_StreamPosFrames@{fg text}

@{b}NAME@{ub}
   @{b}MMA_StreamPosFrames@{ub} (V51) [..G.Q], UQUAD*


@{b}FUNCTION@{ub}
   Returns current absolute stream position in sample frames. It is exactly
   the number of the whole sample frames pulled from object's output. As
   ima-adpcm.decoder object has no information about sound channels, it
   queries the object connected to the input of MMA_Sound_Channels with
   @{"MMM_GetPortFwd" Link "multimedia.class.guide/MMM_GetPortFwd"}() method.


@{b}NOTES@{ub}
   This is a 64-bit attribute passed by pointer to UQUAD variable, not by
   value.


@endnode
@Node "MMA_StreamPosTime" "ima-adpcm.decoder/MMA_StreamPosTime"
@{fg shine}ima-adpcm.decoder/MMA_StreamPosTime@{fg text}

@{b}NAME@{ub}
   @{b}MMA_StreamPosTime@{ub} (V51) [..G.Q], UQUAD*


@{b}FUNCTION@{ub}
   Returns absolute stream time position in microseconds. This time position
   is strictly based on MMA_Sound_SampleRate, and reflects only the whole
   sample frames already pulled from the object output. The exact formula
   is:

   time_pos = whole_frames_pulled / MMA_Sound_SampleRate

   The class queries the object connected to the object's input about
   MMA_Sound_SampleRate and MMA_Sound_Channels with @{"MMM_GetPortFwd" Link "multimedia.class.guide/MMM_GetPortFwd"}() method.


@{b}NOTES@{ub}
   This is a 64-bit attribute passed by pointer to UQUAD variable, not by
   value.

   Returned time is not in any way related to playback time for two reasons:
   firstly, there can be an unknown number of buffers between the decoder
   and the output, secondly, playback samplerate may be different than those
   specified in the stream header.


@endnode
@Node "MMM_Pull" "ima-adpcm.decoder/MMM_Pull"
@{fg shine}ima-adpcm.decoder/MMM_Pull@{fg text}

@{b}NAME@{ub}
   @{b}MMM_Pull@{ub} (V50)


@{b}SYNOPSIS@{ub}
   bytes = DoMethod(obj, @{b}MMM_Pull@{ub}, ULONG port, APTR buffer, ULONG length);


@{b}FUNCTION@{ub}
   Places required amount of sound common format data (in bytes) in the
   specified buffer. The method calculates how many bytes it must pull from
   the previous object, to get required amount of output. Then data are
   pulled, converted and placed in the buffer. Note that requested number of
   bytes should be a multiply of sample frame size. If it is not, it will be
   rounded down to the nearest sample frame boundary, left bytes are
   undefined.


@{b}INPUTS@{ub}
   - obj, object to perform the method on.
   - port, number of port is always 1 (the output port).
   - buffer, a memory buffer for pulled data, must be aligned to 16-byte
     boundary (preferrably allocated with MediaAllocMem()).
   - length, amount of pulled data in bytes. Will be rounded down to the
     nearest sample frame boundary.


@{b}RESULT@{ub}
   - bytes, number of bytes pulled actually.


@endnode

